{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "from memory_profiler import profile\n",
    "import os, random, math, argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model_ABDG_v2 import ProteinGCN\n",
    "# from data import \n",
    "from data import ProteinDataset, get_train_val_test_loader,collate_pool\n",
    "from utils import randomSeed\n",
    "import config as cfg\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_torch(x):\n",
    "    \"\"\"\n",
    "    Convert from a torch tensor to numpy array\n",
    "    \"\"\"\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_way = 5 # Number of ways\n",
    "K_shot = 5\n",
    "Q_queryperclass = 1 # K_shot is the number of shots\n",
    "\n",
    "aa_num_neighbors = 1 #How many adjacent amino acids to the target?\n",
    "\n",
    "ISPROTEINGCN_EMBEDDED = True\n",
    "# Data loading parameters only\n",
    "# max_amino=200\n",
    "# num_writers = 20    # Number of drawings per character\n",
    "# num_alphabets = 50   # Number of alphabets in Omniglot (explained below)\n",
    "# num_characters = 1623 # Number of characters in the entire Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device being used:  cpu\n",
      "No protein directory given for validation!! Please recheck the split ratios, ignore if this is intended.\n",
      "Testing on 464 protein directories:\n"
     ]
    }
   ],
   "source": [
    "args = {'name': 'abdg_demo',\n",
    "            'pkl_dir': '/home/ambeck/6.883ProteinDocking/data/firstDB5try/',\n",
    "            'protein_dir': '/home/ambeck/6.883ProteinDocking/data/firstDB5try/',\n",
    "            'save_dir': './data/pkl/results/',\n",
    "            'id_prop': 'protein_id_prop.csv',\n",
    "            'atom_init': 'protein_atom_init.json',\n",
    "            'pretrained': './pretrained/pretrained.pth.tar',\n",
    "            'avg_sample': 500,\n",
    "            'seed': 1234,\n",
    "            'epochs': 0,\n",
    "            'batch_size': 1,\n",
    "            'train': 0.0,\n",
    "            'val': 0.0,\n",
    "            'test': 1.0,\n",
    "            'testing': False,\n",
    "            'lr': 0.001, 'h_a': 64, 'h_g': 32,\n",
    "            'n_conv': 4, 'save_checkpoints': True,\n",
    "            'print_freq': 10, \n",
    "            'workers': 1,\n",
    "           }\n",
    "print('Torch Device being used: ', cfg.device)\n",
    "\n",
    "# create the savepath\n",
    "savepath = args[\"save_dir\"] + str(args[\"name\"]) + '/'\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "randomSeed(args[\"seed\"])\n",
    "\n",
    "# create train/val/test dataset separately\n",
    "assert os.path.exists(args[\"protein_dir\"]), '{} does not exist!'.format(args[\"protein_dir\"])\n",
    "dirs_label = [d[:10] for d in os.listdir(args[\"pkl_dir\"]) if not d.startswith('.DS_Store')]\n",
    "# all_dirs = [d for d in os.listdir(args[\"protein_dir\"]) if not d.startswith('.DS_Store')]\n",
    "base_dir=set(dirs_label)\n",
    "dir_r = []\n",
    "dir_l = []\n",
    "dir_r.extend(d+'r_u_cleane.pkl' for d in base_dir)\n",
    "dir_l.extend(d+'l_u_cleane.pkl' for d in base_dir)\n",
    "all_dirs = []\n",
    "for r,l in zip(dir_r, dir_l):\n",
    "    all_dirs.append(r)\n",
    "    all_dirs.append(l)\n",
    "\n",
    "dir_len = len(all_dirs)\n",
    "indices = list(range(dir_len))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = math.floor(args[\"train\"] * dir_len)\n",
    "val_size = math.floor(args[\"val\"] * dir_len)\n",
    "test_size = math.floor(args[\"test\"] * dir_len)\n",
    "\n",
    "if val_size == 0:\n",
    "    print(\n",
    "        'No protein directory given for validation!! Please recheck the split ratios, ignore if this is intended.')\n",
    "if test_size == 0:\n",
    "    print('No protein directory given for testing!! Please recheck the split ratios, ignore if this is intended.')\n",
    "\n",
    "test_dirs = all_dirs[:test_size]\n",
    "train_dirs = all_dirs[test_size:test_size + train_size]\n",
    "val_dirs = all_dirs[test_size + train_size:test_size + train_size + val_size]\n",
    "print('Testing on {} protein directories:'.format(len(test_dirs)))\n",
    "\n",
    "@profile\n",
    "def loadProteinDataSetAndModel():\n",
    "\n",
    "    dataset = ProteinDataset(args[\"pkl_dir\"], args[\"id_prop\"], args[\"atom_init\"], random_seed=args[\"seed\"])\n",
    "\n",
    "    print('Dataset length: ', len(dataset))\n",
    "\n",
    "    # load all model args from pretrained model\n",
    "    if args[\"pretrained\"] is not None and os.path.isfile(args[\"pretrained\"]):\n",
    "        print(\"=> loading model params '{}'\".format(args[\"pretrained\"]))\n",
    "        model_checkpoint = torch.load(args[\"pretrained\"], map_location=lambda storage, loc: storage)\n",
    "        model_args = argparse.Namespace(**model_checkpoint['args'])\n",
    "        # override all args value with model_args\n",
    "        args[\"h_a\"] = model_args.h_a\n",
    "        args[\"h_g\"] = model_args.h_g\n",
    "        args[\"n_conv\"] = model_args.n_conv\n",
    "        args[\"random_seed\"] = model_args.seed\n",
    "        args[\"lr\"] = model_args.lr\n",
    "\n",
    "        print(\"=> loaded model params '{}'\".format(args[\"pretrained\"]))\n",
    "    else:\n",
    "        print(\"=> no model params found at '{}'\".format(args[\"pretrained\"]))\n",
    "\n",
    "    args[\"random_seed\"] = args[\"seed\"]\n",
    "    structures, _, _ = dataset[0]\n",
    "    \n",
    "    h_b = structures[1].shape[-1]\n",
    "    args['h_b'] = h_b  # Dim of the bond embedding initialization\n",
    "\n",
    "    # Use DataParallel for faster training\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs and Data Parallel Model.\")\n",
    "    # print(kwargs)\n",
    "    model = ProteinGCN(**args)\n",
    "    return model, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file <ipython-input-4-ffed259b5ef1>\n",
      "NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n",
      "Dataset length:  920\n",
      "=> loading model params './pretrained/pretrained.pth.tar'\n",
      "=> loaded model params './pretrained/pretrained.pth.tar'\n",
      "Let's use 0 GPUs and Data Parallel Model.\n"
     ]
    }
   ],
   "source": [
    "model, dataset = loadProteinDataSetAndModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_train_val_test_loader(dataset, train_dirs, val_dirs, test_dirs,\n",
    "                                                                      collate_fn    = collate_pool,\n",
    "                                                                      num_workers   = args[\"workers\"],\n",
    "                                                                        batch_size    = args[\"batch_size\"],\n",
    "                                                                      pin_memory    = False,\n",
    "                                                                      predict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputHACK(inputs):\n",
    "    return [inputs[0], inputs[1], inputs[2], inputs[4], inputs[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Network Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(names, folder):\n",
    "    '''names = list of protein_names, folder = 'emb_ligand', etc '''\n",
    "    dict_out={}\n",
    "    for n in names:\n",
    "        filename = os.path.join(fullpath,folder,n +'.pkl')\n",
    "        if os.path.exists(filename):\n",
    "            if \"emb\" in filename:\n",
    "                amino_emb,_ = torch.load(filename)\n",
    "            else:\n",
    "                amino_emb = torch.load(filename)[2].squeeze()\n",
    "            dict_out[n] = amino_emb\n",
    "    return dict_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAdjacencyMatrix(pdb,pdb_dir,chooseBound=True):\n",
    "    #DB5 specific\n",
    "    boundchar = 'b'\n",
    "    if not chooseBound:\n",
    "        boundchar = 'u'\n",
    "    #[(500, 64, 'A'), (1116, 141), 'A'],\n",
    "    adjacencies_full = np.load(os.path.join(pdb_dir, pdb, f'{pdb}_{boundchar}_adjacencies.npy'),allow_pickle=True)\n",
    "\n",
    "    adjacencies_short = [[a[0][1], a[1][1]] for a in adjacencies_full]\n",
    "    #Correct for the 1-indexing of the PDB to the 0-indexing of the ProteinGCN\n",
    "    adjacencies_short = np.array(adjacencies_short)-1\n",
    "    return adjacencies_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading amino embeddings from files and putting into dictionaries\n",
    "fullpath='/mnt/disks/amanda200/bounddb5_processed/'\n",
    "protein_names=torch.load(fullpath + 'names.pkl')\n",
    "#NOTE: there was an extra addition 'prot' that must be removed here\n",
    "protein_names.remove('prot')\n",
    "\n",
    "proteins = [n for n in protein_names]\n",
    "if ISPROTEINGCN_EMBEDDED:\n",
    "    ligands = make_dictionary(protein_names, 'emb_ligand')\n",
    "    receptors = make_dictionary(protein_names, 'emb_receptor')        \n",
    "else:\n",
    "    ligands = make_dictionary(protein_names, 'ligand')\n",
    "    receptors = make_dictionary(protein_names, 'receptor')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  torch.Size([1, 1032])\n",
      "1:  torch.Size([1, 1032, 50, 43])\n",
      "2:  torch.Size([1, 1032, 50])\n",
      "3:  torch.Size([1, 1032])\n",
      "4:  torch.Size([1, 1032])\n"
     ]
    }
   ],
   "source": [
    "f = torch.load('/mnt/disks/amanda200/bounddb5_processed/ligand/3S9D.pkl')\n",
    "for i in np.arange(len(f)):\n",
    "    print(f\"{i}:  {f[i].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500   64]\n",
      "[2130   64]\n"
     ]
    }
   ],
   "source": [
    "ligand_sizes = [ligands[n].size() for n in ligands.keys()]\n",
    "max_amino_l = np.max(ligand_sizes,0)\n",
    "receptor_sizes = [receptors[n].size() for n in receptors.keys()]\n",
    "max_amino_r = np.max(receptor_sizes,0)\n",
    "\n",
    "print(max_amino_l)\n",
    "print(max_amino_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={}\n",
    "for protein in protein_names:\n",
    "    # Load the adjacencey matrix that is a set of pairs of amino acids between ligand and receptors\n",
    "    adj = torch.load(os.path.join(fullpath,'adjacencies', protein +'.pkl'))\n",
    "    #Get the indices\n",
    "    ligand_no = [adj[n][0] for n in np.arange(len(adj))]\n",
    "    receptor_no = [adj[n][1] for n in np.arange(len(adj))]\n",
    "    #Make a dense adjacency matrix \n",
    "    num_aminos_l = ligands[protein].shape[0]\n",
    "    num_aminos_r = receptors[protein].shape[0]\n",
    "    label = torch.zeros((num_aminos_l,num_aminos_r))\n",
    "    label[ligand_no,receptor_no]=1\n",
    "    labels[protein]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleProteinTaskLoader:\n",
    "    def __init__(self, protein_ligands,protein_receptors,complex_adjacencies, batch_size):\n",
    "        \"\"\"\n",
    "        Do not concatenate the characters from different proteins together. When sampling a task,\n",
    "        sample a protein first before sampling the shots within the protein\n",
    "\n",
    "        proteins: a dictionary mapping from protein names to arrays of size (num_aminos, feat_size),\n",
    "            where num_aminos is the number of amino acids in the protein\n",
    "        batch_size: number of tasks to generate at once\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        #Making the strong assumption that ligands and receptors have the same protein names \n",
    "        self.protein_names = list(protein_ligands.keys())\n",
    "        self.protein_ligands = protein_ligands\n",
    "        self.protein_receptors = protein_receptors\n",
    "        self.complex_adjacencies = complex_adjacencies\n",
    "        self.nbd = 1+2*aa_num_neighbors #The neigborhood around an amino acid\n",
    "        self.h_b = 64 #The size of the hidden layer\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Define this class as an iterable that yields a batch of tasks at each iteration when used in a for-loop.\n",
    "    \n",
    "        return: a batch of tasks\n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "            batch = torch.as_tensor([])\n",
    "            y_total = [] #all the labels\n",
    "            for _ in range(self.batch_size):\n",
    "                # Randomly sample a protein, then sample N_way classes from this proteins positive and negative\n",
    "                # matching amino acids \n",
    "                protein_name = np.random.choice(self.protein_names)\n",
    "                protein_ligand = self.protein_ligands[protein_name]\n",
    "                \n",
    "                protein_receptor = self.protein_receptors[protein_name]\n",
    "                adjacencies = self.complex_adjacencies[protein_name]\n",
    "                \n",
    "                num_class = 2 #bind or doesn't bind\n",
    "\n",
    "                #Initialize the set of positive and negative labels\n",
    "                pos_labels_lig,pos_labels_receptor = np.where(self.complex_adjacencies[protein_name]>0)\n",
    "                neg_labels_lig,neg_labels_receptor = np.where(self.complex_adjacencies[protein_name]==0)\n",
    "                \n",
    "                #Get N_way positive samples, N_way negative samples\n",
    "                #NOTE: This even split of pos/neg is an important meta parameter\n",
    "                pos_indices = np.random.choice(np.arange(len(pos_labels_lig)), size=N_way, replace=False)\n",
    "                #NOTE: The negative samples can be taken from non-surface residues, which could be uninformative\n",
    "                neg_indices = np.random.choice(np.arange(len(neg_labels_lig)), size=N_way, replace=False)\n",
    "                \n",
    "                #Here are the indices to positive/negative amino acid pairs and their labels\n",
    "                indices_ligand = np.concatenate(( pos_labels_lig[pos_indices],neg_labels_lig[neg_indices]),axis=0);\n",
    "                indices_receptor = np.concatenate((pos_labels_receptor[pos_indices],neg_labels_receptor[neg_indices]),axis=0);\n",
    "\n",
    "                classes = np.concatenate((np.ones(N_way),np.zeros(N_way)),axis=0);\n",
    "                #When making the batch, shuffle so we don't memorize positions\n",
    "                permuted_indices = np.random.permutation(np.arange(len(classes)))\n",
    "                                                                         \n",
    "                supports_queries = torch.zeros((N_way + N_way,2,self.nbd, self.h_b)) \n",
    "                y = torch.zeros(N_way + N_way) #used to be K_shot + Q_queryperclass\n",
    "                for i,p in enumerate(permuted_indices):\n",
    "                    #(2, max_amino*num_receptors, max_amino*num_ligands)\n",
    "                    y[i] = classes[p]\n",
    "                    #Grow the local neighborhood with self.nbd\n",
    "                    for j,n in enumerate(np.arange(-aa_num_neighbors,aa_num_neighbors+1)):\n",
    "                        if (indices_ligand[p]+n) in range(0,protein_ligand.shape[0]):\n",
    "                            supports_queries[i,0,j,:] = protein_ligand[indices_ligand[p]+n,:]\n",
    "                        else:\n",
    "                            supports_queries[i,0,j,:] = 0\n",
    "                        if (indices_receptor[p]+n) in range(0,protein_receptor.shape[0]):    \n",
    "                            supports_queries[i,1,j,:] = protein_receptor[indices_receptor[p]+n,:]\n",
    "                        else:\n",
    "                            supports_queries[i,1,j,:] = 0\n",
    "\n",
    "                batch = torch.cat([batch,torch.as_tensor(supports_queries).unsqueeze(0)],dim=0)\n",
    "                y_total.append(np.array(y))\n",
    "           \n",
    "            yield np.array(y_total),batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullProteinTaskLoader:\n",
    "    def __init__(SingleProteinTaskLoader):\n",
    "        '''\n",
    "        Inputs should be LSTM proteins so they are all the same length\n",
    "        '''\n",
    "        \n",
    "  \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        return: a batch of tasks, which should be a tensor shaped\n",
    "                (batch_size, max_amino*no_receptor, max_amino*no_ligands, feat_no*2 )\n",
    "                labels for each task, which should be a tensor shaped\n",
    "                (batch_size, max_amino*no_receptor, max_amino*no_ligands) filled with 1 or 0\n",
    "            \n",
    "            \n",
    "            What are the classes? yes/no or pairs? Do we want to input the receptors and ligands separately? \n",
    "        \"\"\"\n",
    "        while True:\n",
    "                protein_name = np.random.choice(self.protein_names)\n",
    "                protein_ligand = self.protein_ligands[protein_name]\n",
    "                batch = torch.as_tensor([])\n",
    "                for _ in range(self.batch_size):\n",
    "                    protein_type = np.random.choice(np.arange(2))\n",
    "                    if bool(protein_type):\n",
    "                        new_task = self.protein_ligands[protein_name]\n",
    "                    batch = torch.cat([batch,torch.as_tensor])\n",
    "\n",
    "                protein_receptor = self.protein_receptors[protein_name]\n",
    "                adjacencies = self.complex_adjacencies[protein_name]\n",
    "                yield (protein_name, protein_ligand) # Shape (batch_size, N_way, K_shot + Q_queryperclass, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, feat_size=64, bottleneck=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Your code here ###\n",
    "        \n",
    "        self.encode_hidden1 = nn.Sequential(\n",
    "            nn.Linear(in_features=feat_size,\n",
    "            out_features= bottleneck^3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encode_hidden2 = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck^3,\n",
    "            out_features= bottleneck^2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.encode_output = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck^2,\n",
    "            out_features=bottleneck),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )   \n",
    "        self.decode_hidden = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck,\n",
    "            out_features=bottleneck^2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decode_output1 = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck^2,\n",
    "            out_features=bottleneck^3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decode_output2 = nn.Sequential(\n",
    "            nn.Linear(in_features=bottleneck^3,\n",
    "            out_features=feat_size),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, feats,labels):\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "\n",
    "        \"\"\"\n",
    "        window_size, feature_size = feats.shape\n",
    "\n",
    "        loss, accuracy = self.predictor(feats.view(-1,feature_size))\n",
    "\n",
    "        return loss, accuracy\n",
    "        \n",
    "    def predictor(self, features):\n",
    "        \n",
    "        newstate = self.encode_hidden1(features)\n",
    "        newstate = self.encode_hidden2(newstate)\n",
    "        newstate = self.encode_output(newstate)\n",
    "        newstate = self.decode_hidden(newstate)\n",
    "        newstate = self.decode_output1(newstate)\n",
    "        relations = self.decode_output2(newstate)\n",
    "  \n",
    "        loss = F.mse_loss(relations.view(-1,1).squeeze(), features.view(-1,1).squeeze())\n",
    "\n",
    "        #accuracy = (torch.round(relations.squeeze()) == labels_.squeeze()).float().mean()\n",
    "        accuracy = 0 #accuracy is just a place holder for now.\n",
    "        return torch.as_tensor(loss), torch.as_tensor(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeLayer(nn.Module):\n",
    "    def __init__(self, window_size=100, bottleneck=8):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=window_size*bottleneck,\n",
    "            out_features=window_size^2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "    def forward(self, feats,labels):\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "        \"\"\"\n",
    "        #print(f\"Feats size: {feats.size()}\")\n",
    "        window_size, feature_size = feats.shape\n",
    "\n",
    "        loss, accuracy = self.predictor(feats.view(-1,feature_size),labels)\n",
    "        #convolve across window?\n",
    "        return loss, accuracy\n",
    "        \n",
    "    def predictor(self, features, labels):\n",
    "        \n",
    "        print(features.size())\n",
    "        relations = self.fc1(features)\n",
    "\n",
    "        loss = F.mse_loss(relations.view(-1,1).squeeze(), features.view(-1,1).squeeze())\n",
    "        \n",
    "        #accuracy = (torch.round(relations.squeeze()) == labels_.squeeze()).float().mean()\n",
    "        accuracy = (round(relations.view(-1,1)) == labels).float().mean()\n",
    "        return torch.as_tensor(loss), torch.as_tensor(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, num_steps, print_prob=False):\n",
    "    \"\"\"\n",
    "    Train the input neural network for num_steps\n",
    "    \n",
    "    net: an instance of MatchingNetwork, PrototypicalNetwork, or RelationNetwork\n",
    "    num_steps: number of batches to train for\n",
    "    \n",
    "    return: the trained net, the training accuracies per step, and the validation accuracies per 100 steps\n",
    "    \"\"\"\n",
    "    net = net.to(device)\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=1e-3,weight_decay=0.1)\n",
    "    train_accuracies = []\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_losses=[]\n",
    "    count_global=0\n",
    "    val_count_global=0\n",
    "\n",
    "    for step, data in zip(range(num_steps), train_metadataset):\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss, accuracy = net(torch.as_tensor(data, dtype=torch.float32, device=device),0)\n",
    "\n",
    "        loss.backward(retain_graph=True,create_graph=True)\n",
    "        opt.step()\n",
    "        train_loss, train_accuracy = map(from_torch, (loss, accuracy))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "        if (step + 1) % 100 == 0:\n",
    "            val_metadataset = val_meta_blocks[val_count_global,:,:,:].squeeze()\n",
    "            for n in np.arange(val_metadataset.size(0)):\n",
    "                loss_vec=[]\n",
    "                temp_loss, val_accuracy = evaluate(net, val_metadataset[n,:,:]) \n",
    "                loss_vec.append(temp_loss)\n",
    "            val_loss = np.mean(loss_vec)\n",
    "            val_count_global+=1\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print('step=%s   train(loss=%.5g, accuracy=%.5g)  val(loss=%.5g, accuracy=%.5g)' % (\n",
    "                step + 1, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "            ))\n",
    "            if print_prob:\n",
    "                print(np.concatenate((val_relations, val_labels.reshape(-1,1)),axis=1))\n",
    "    return net, train_accuracies, train_losses, val_accuracies, val_losses\n",
    "\n",
    "def evaluate(net, metadataset):\n",
    "    \"\"\"\n",
    "    Evalate the trained net on either the validation or test metadataset\n",
    "    \n",
    "    \"\"\"\n",
    "    with torch.no_grad(): # Evaluate without gradients\n",
    "\n",
    "        loss, accuracy = net(torch.as_tensor(metadataset.squeeze(), dtype=torch.float32, device=device), 0)\n",
    "        loss, accuracy = map(from_torch, (loss, accuracy))\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_proteins = len(protein_names)\n",
    "num_train, num_val = int(num_proteins * 0.6), int(num_proteins * 0.2)\n",
    "\n",
    "# Train, val, test sets\n",
    "#Note that we've already shuffled the proteins so we can simply divide the indices in order\n",
    "train_val_test_splits = np.split(list(protein_names), [num_train, num_train + num_val])\n",
    "\n",
    "\n",
    "sets = [{n: ligands[n] for n in pdbids} for pdbids in train_val_test_splits]\n",
    "ligands_train, ligands_test, ligands_val = sets\n",
    "\n",
    "sets = [{n: receptors[n] for n in pdbids} for pdbids in train_val_test_splits]\n",
    "receptors_train, receptors_test, receptors_val = sets\n",
    "\n",
    "sets = [{n: labels[n] for n in pdbids} for pdbids in train_val_test_splits]\n",
    "labels_train, labels_test, labels_val = sets\n",
    "\n",
    "\n",
    "train_metadataset = SingleProteinTaskLoader(ligands_train,receptors_train, labels_train,batch_size=64)\n",
    "val_metadataset = SingleProteinTaskLoader(ligands_val,receptors_val, labels_val,batch_size=100)\n",
    "test_metadataset = SingleProteinTaskLoader(ligands_test,receptors_test, labels_test,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowedProteinTaskLoader:\n",
    "    def __init__(self, protein_ligands, protein_receptors,window_length, window_overlap):\n",
    "        '''\n",
    "        Inputs should be LSTM proteins so they are all the same length\n",
    "        '''\n",
    "\n",
    "        self.window=window_length #input the atom numbers?\n",
    "        self.overlap=window_overlap\n",
    "        self.protein_names = list(protein_ligands.keys())\n",
    "        self.protein_ligands = protein_ligands\n",
    "        self.protein_receptors = protein_receptors\n",
    "\n",
    "  \n",
    "    def create_batch(self):\n",
    "        \"\"\"\n",
    "        return: a batch of tasks, which should be a tensor shaped\n",
    "                (batch_size, window_size, feature_size) where batch_size = # windows per protein * protein\n",
    "                the indexes used, dictionary with keys = protein names\n",
    "                value of dictionary = torch tensor shaped (2*number of windows in protein or ligand, window_length)\n",
    "        \"\"\"\n",
    "        batch = torch.as_tensor([])\n",
    "        protein_idx = dict.fromkeys(self.protein_names, [])\n",
    "        ligand_windows = dict.fromkeys(self.protein_names, [])\n",
    "        receptor_windows = dict.fromkeys(self.protein_names, [])\n",
    "        protein_count = 0\n",
    "        for protein in self.protein_names:\n",
    "            #print(protein)\n",
    "            ligand = self.protein_ligands[protein]\n",
    "            ligand_len = ligand.size(0)\n",
    "            receptor = self.protein_receptors[protein]\n",
    "            receptor_len = receptor.size(0)\n",
    "            receptor_window = 0\n",
    "            ligand_window = 0\n",
    "            #window from front and back?\n",
    "            idx_all = torch.as_tensor([])\n",
    "            while (ligand_window*self.overlap+self.window) <= ligand_len:\n",
    "                idx_forward = torch.arange(ligand_window*self.overlap, ligand_window*self.overlap + self.window)\n",
    "                batch = torch.cat([batch, ligand[idx_forward,:].unsqueeze(dim=0)], dim=0)\n",
    "                idx_all = torch.cat([idx_all, idx_forward.unsqueeze(dim=0)],dim=0)\n",
    "                idx_back = torch.arange(ligand_len-(self.overlap*ligand_window)-1,ligand_len-(self.overlap*ligand_window)-self.window-1,-1)\n",
    "#                     print(max(idx_back))\n",
    "#                     print(min(idx_back))\n",
    "#                     print(len(idx_back))\n",
    "                batch = torch.cat([batch, ligand[idx_back,:].unsqueeze(dim=0)], dim=0)\n",
    "                idx_all = torch.cat([idx_all, idx_back.unsqueeze(dim=0)],dim=0)\n",
    "                ligand_window +=1\n",
    "                #print(window_num)\n",
    "\n",
    "            while (receptor_window*self.overlap+self.window) <= receptor_len:\n",
    "                idx_forward = torch.arange(receptor_window*self.overlap, receptor_window*self.overlap + self.window)\n",
    "                batch = torch.cat([batch, receptor[idx_forward,:].unsqueeze(dim=0)], dim=0)\n",
    "                idx_all = torch.cat([idx_all, idx_forward.unsqueeze(dim=0)],dim=0)\n",
    "                idx_back = torch.arange(receptor_len-(self.overlap*receptor_window)-1,receptor_len-(self.overlap*receptor_window)-self.window-1,-1)\n",
    "                batch = torch.cat([batch, receptor[idx_back,:].unsqueeze(dim=0)], dim=0)\n",
    "                idx_all = torch.cat([idx_all, idx_back.unsqueeze(dim=0)],dim=0)\n",
    "                receptor_window +=1\n",
    "                #print(window_num)\n",
    "            protein_idx[protein] = idx_all\n",
    "            receptor_windows[protein] = receptor_window\n",
    "            ligand_windows[protein] = ligand_window\n",
    "            protein_count+=1\n",
    "            print(protein_count)\n",
    "\n",
    "\n",
    "        return batch, protein_idx, ligand_windows, receptor_windows # Shape (batch_size, N_way, K_shot + Q_queryperclass, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows = WindowedProteinTaskLoader(ligands_train,receptors_train, window_length=100, window_overlap=50)\n",
    "val_windows = WindowedProteinTaskLoader(ligands_val,receptors_val, window_length=100, window_overlap=50)\n",
    "#test_windows = WindowedProteinTaskLoader(ligands_test,receptors_test, window_length=100, window_overlap=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=100   train(loss=117.43, accuracy=0)  val(loss=79.923, accuracy=0)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "autonet=AutoEncoder()\n",
    "train_steps = 100\n",
    "dump, train_accs, train_loss, val_accs, val_loss = train(autonet, train_steps)\n",
    "print(len(val_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1,sharex=True)\n",
    "ax1.plot((1 + np.arange(len(train_accs))), train_accs, label=\"Training Accuracy\")\n",
    "ax1.plot((1 + np.arange(len(val_accs)))*100, val_accs, label=\"Validation Accuracy\")\n",
    "ax2.set_xlabel('training step')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot((1 + np.arange(len(train_loss))), train_loss, label=\"Training Loss\")\n",
    "ax2.plot((1 + np.arange(len(val_loss))) * 100, val_loss, label=\"Validation Loss\")\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Extended Pipeline/Future Directions. (Under Construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatAutoEncoder(AutoEncoder):\n",
    "    def __init__(self): #depth is protein_no*protein_no\n",
    "        \"\"\"\n",
    "        Define Linear layers for Autoencoder\n",
    "        bottleneck = number of nodes at bottleneck\n",
    "        \"\"\"\n",
    "        #Questions:\n",
    "        #1. How do we deal with variable length proteins? zeropad?\n",
    "        #2. How do we go from autoencoder output to protein structure?\n",
    "                #can we do this with proteinGCN? Do we learn an adjacency matrix?\n",
    "        #3. Convolve or LSTM along protein to take advantage of chain structure?\n",
    "        \n",
    "        # The backbone for Relation Network doesn't max pool for the last two convolution blocks\n",
    "        super().__init__(bottleneck=8)\n",
    "        ### Your code here ###\n",
    "\n",
    "        self.decode_cat_hidden = nn.Sequential(\n",
    "            nn.Linear(in_features=2*bottleneck,\n",
    "            out_features=(2*bottleneck)^2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.decode_cat_output = nn.Sequential(\n",
    "            nn.Linear(in_features=(2*bottleneck)^2,\n",
    "            out_features=(2*bottleneck)^3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    "\n",
    "    def predictor(self, features, labels_):\n",
    "        \"\"\"\n",
    "        receptor_emb = tensor of size (batch_no, task_no, r/l,protein_length?, feature size)\n",
    "        return: a tuple (loss, accuracy) of two torch.float32 scalars representing the mean loss and\n",
    "            mean accuracy of the batch\n",
    "        \"\"\"\n",
    "        ### Your code here ###\n",
    "        rec_state = self.encode_hidden(features[:,:,0,:,:].view(-1, nbd, feat_size))\n",
    "        rec_state = self.encode_output(rec_state)\n",
    "        lig_state = self.encode_hidden(features[:,:,1,:,:].view(-1, nbd, feat_size))\n",
    "        lig_state = self.encode_output(lig_state)\n",
    "        \n",
    "        hidden_cat = torch.cat([rec_state,lig_state],dim=2)\n",
    "        newstate = self.decode_hidden(hidden_cat)\n",
    "        relations = self.decode_output(newstate)\n",
    "        \n",
    "        #fully connected layer on decoded output for labels or adj matrix?\n",
    "        #do we want to learn embedded bound proteins from embedded unbound proteins?\n",
    "        #train model on bound to bound then use as initialization for bound to unbound?\n",
    "        \n",
    "        loss = F.mse_loss(relations.squeeze(), labels_.squeeze())\n",
    "        accuracy = (torch.round(relations.squeeze()) == labels_.squeeze()).float().mean()\n",
    "        \n",
    "        \n",
    "        return relations, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decoder(net, num_steps, print_prob=False):\n",
    "    \"\"\"\n",
    "    Train the input neural network for num_steps\n",
    "    \n",
    "    net: an instance of MatchingNetwork, PrototypicalNetwork, or RelationNetwork\n",
    "    num_steps: number of batches to train for\n",
    "    \n",
    "    return: the trained net, the training accuracies per step, and the validation accuracies per 100 steps\n",
    "    \"\"\"\n",
    "    net = net.to(device)\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=1e-3,weight_decay=0.1)\n",
    "    train_accuracies = []\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_losses=[]\n",
    "    count_global=0\n",
    "    val_count_global=0\n",
    "    #print(train_metadataset)\n",
    "    for step, data, label in zip(range(num_steps), train_metadataset, train_latent_labels):\n",
    "        #print(step)\n",
    "        #print(data.size())\n",
    "        #labels_ = torch.as_tensor(y) #Adding the _ because labels is a globally defined variable\n",
    "        #batch_size = data.size(0)#Will this print the correct size?\n",
    "        #print(f\"batch size of task is: {data.size()}\")\n",
    "        \n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss, accuracy = net(torch.as_tensor(data, dtype=torch.float32, device=device),train_latent_labels)\n",
    "        #loss, accuracy = net(torch.as_tensor(data),0)\n",
    "#         if step == 0:\n",
    "#             loss.backward(retain_graph=True)\n",
    "#         else:\n",
    "#             loss.backward()\n",
    "        #print(loss.size())\n",
    "        loss.backward(retain_graph=True,create_graph=True)\n",
    "        opt.step()\n",
    "        train_loss, train_accuracy = map(from_torch, (loss, accuracy))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "        if (step + 1) % 100 == 0:\n",
    "            val_metadataset = val_decoder_blocks[val_count_global,:,:,:].squeeze()\n",
    "            val_labelset = val_label_blocks[val_count_global,:,:].squeeze()\n",
    "            for n in np.arange(val_metadataset.size(0)):\n",
    "                loss_vec=[]\n",
    "                temp_loss, val_accuracy = evaluate_decoder(net, val_metadataset[n,:,:], val_labelset) #whetre are these defined?\n",
    "                loss_vec.append(temp_loss)\n",
    "            val_loss = np.mean(loss_vec)\n",
    "            val_count_global+=1\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            print('step=%s   train(loss=%.5g, accuracy=%.5g)  val(loss=%.5g, accuracy=%.5g)' % (\n",
    "                step + 1, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "            ))\n",
    "            if print_prob:\n",
    "                print(np.concatenate((val_relations, val_labels.reshape(-1,1)),axis=1))\n",
    "    return net, train_accuracies, train_losses, val_accuracies, val_losses\n",
    "\n",
    "def evaluate_decoder(net, metadataset, metalabels):\n",
    "    \"\"\"\n",
    "    Evalate the trained net on either the validation or test metadataset\n",
    "    \n",
    "    net: an instance of MatchingNetwork, PrototypicalNetwork, or RelationNetwork\n",
    "    metadataset: validation or test metadataset\n",
    "    \n",
    "    return: a tuple (loss, accuracy) of Python scalars\n",
    "    \"\"\"\n",
    "    with torch.no_grad(): # Evaluate without gradients\n",
    "\n",
    "        loss, accuracy = net(torch.as_tensor(metadataset.squeeze(), dtype=torch.float32, device=device), metalabels)\n",
    "        loss, accuracy = map(from_torch, (loss, accuracy))\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MixLatentState(latents, indexes, names, train_lw, train_rw, adj):\n",
    "    ''' Want to build concatenated ligand and receptor sets. concatenate by windows (all combinations)\n",
    "    adjacency matrix is receptor x ligand\n",
    "    '''\n",
    "    total_windows=0\n",
    "    protein_idx=0\n",
    "    batch=torch.as_tensor([])\n",
    "    labels=torch.as_tensor([])\n",
    "    for protein in names:\n",
    "        temp_index=torch.as_tensor(indexes[protein],dtype=torch.long)\n",
    "        temp_label=torch.as_tensor(adj[protein],dtype=torch.long)\n",
    "        assert(temp_index.size(0) == (train_lw[protein]+train_rw[protein])*2)\n",
    "        max_lw=2*train_lw[protein]\n",
    "        max_rw=2*train_rw[protein]\n",
    "        labeltemp=[]\n",
    "        for ii, m in enumerate(np.arange(max_rw)+total_windows+max_lw):\n",
    "            for jj, n in enumerate(np.arange(max_lw)+total_windows):\n",
    "                temp=temp_label[:,temp_index[ii+max_lw]]\n",
    "                temp=temp[temp_index[jj],:]\n",
    "                labels = torch.cat([labels, temp.view(-1,1)],dim=1)\n",
    "                latentcat = torch.cat([latents[n,:,:].unsqueeze(dim=0),latents[m,:,:].unsqueeze(dim=0)],dim=1)\n",
    "                batch = torch.cat([batch, latentcat],dim=0)\n",
    "                \n",
    "        total_windows=total_windows+max_lw+max_rw\n",
    "        print(total_windows)\n",
    "    return batch, labels\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data, train_indexes, train_lw, train_rw = train_windows.create_batch()\n",
    "train_proteins = ligands_train.keys()\n",
    "val_proteins = ligands_val.keys()\n",
    "#pickle.dump((train_data, train_indexes, train_proteins, train_lw, train_rw), open('tr_window50_overlap25.pkl','wb'))\n",
    "val_data, val_indexes, val_lw, val_rw = val_windows.create_batch()\n",
    "#pickle.dump((val_data, val_indexes, val_proteins, val_lw, val_rw), open('val_window50_overlap25.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_metadataset.size()\n",
    "val_temp = val_data[:600,:,:]\n",
    "val_meta_blocks = val_temp.unsqueeze(dim=0).view(20,-1,100,64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find All Encoded/Latent States for DB5 and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batching Encoded Training Data\n",
    "latent_states=torch.as_tensor([])\n",
    "for n in torch.arange(train_data.size(0)):\n",
    "    newstate = autonet.encode_hidden1(train_data[n,:,:])\n",
    "    newstate = autonet.encode_hidden2(newstate)\n",
    "    latenttemp = autonet.encode_output(newstate)\n",
    "    \n",
    "latent_states=torch.cat([latent_states, torch.as_tensor(latenttemp).unsqueeze(dim=0)],dim=0)\n",
    "batched_latents, latent_labels = MixLatentState(latent_states,train_indexes,train_proteins,train_lw,train_rw,label_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Batching Encoded Validation Data\n",
    "val_states=torch.as_tensor([])\n",
    "for n in torch.arange(val_data.size(0)):\n",
    "    newstate = autonet.encode_hidden1(val_data[n,:,:])\n",
    "    newstate = autonet.encode_hidden2(newstate)\n",
    "    latenttemp = autonet.encode_output(newstate)\n",
    "    \n",
    "    latent_states=torch.cat([latent_states, torch.as_tensor(latenttemp).unsqueeze(dim=0)],dim=0)\n",
    "batched_val, val_latent_labels = MixLatentState(latent_states,val_indexes,val_proteins,val_lw,val_rw,label_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 16, 200, 8])\n",
      "torch.Size([100, 16, 10000])\n"
     ]
    }
   ],
   "source": [
    "#Adjust sizes\n",
    "tempval=batched_val[:1600,:,:]\n",
    "val_decoder_blocks = tempval.unsqueeze(dim=0).view(100,-1,200,8)\n",
    "templabels=val_latent_labels.permute(1,0)\n",
    "print(val_decoder_blocks.size())\n",
    "templabels=templabels[:1600,:]\n",
    "val_label_blocks=templabels.unsqueeze(dim=0).view(100,-1,10000)\n",
    "print(val_label_blocks.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Matching Adjacency Matrices as Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_out={}\n",
    "for protein in val_proteins:\n",
    "    # Load the adjacencey matrix that is a set of pairs of amino acids between ligand and receptors\n",
    "    adj = torch.load(os.path.join(fullpath,'adjacencies', protein +'.pkl'))\n",
    "    #Get the indices\n",
    "    ligand_no = [adj[n][0] for n in np.arange(len(adj))]\n",
    "    receptor_no = [adj[n][1] for n in np.arange(len(adj))]\n",
    "    #Make a dense adjacency matrix \n",
    "    num_aminos_l = ligands[protein].shape[0]\n",
    "    num_aminos_r = receptors[protein].shape[0]\n",
    "    label = torch.zeros((num_aminos_l,num_aminos_r))\n",
    "    label[ligand_no,receptor_no]=1\n",
    "    label_out[protein]=torch.as_tensor(label,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AE Pipeline from Encoded proteins to Adjacency Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadataset= train_data\n",
    "val_decoder_blocks=val_metadataset\n",
    "\n",
    "decodenet=DecodeLayer()\n",
    "train_steps = 100\n",
    "train_metadatset\n",
    "dump, train_accs, train_loss, val_accs, val_loss = train_decoder(decodenet, train_steps)\n",
    "print(len(val_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
